{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the CSV to use | instead of , to separate rows, then import [a selection] of the data as a dataframe\n",
    "for_pd = StringIO()\n",
    "with open('../data/accre-jobs-2020.csv') as accre:\n",
    "    for line in accre:\n",
    "        new_line = re.sub(r',', '|', line.rstrip(), count=12)\n",
    "        print (new_line, file=for_pd)\n",
    "for_pd.seek(0)\n",
    "accre_df = pd.read_csv(for_pd, sep='|')#[1000000:1005000] # add this to subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to change NODES and CPU to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df['NODES'] = accre_df['NODES'].astype(int)\n",
    "accre_df['CPUS'] = accre_df['CPUS'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We also need to convert the times to total seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This splits the hour, minutes, seconds from the __TIME columns\n",
    "accre_df['hours_min_sec_req'] = accre_df['REQTIME'].str[-8:]\n",
    "accre_df['hours_min_sec_used'] = accre_df['USEDTIME'].str[-8:]\n",
    "\n",
    "## This splits the day from the ___TIME columns\n",
    "accre_df['day_req'] = accre_df['REQTIME'].str.extract('(.*?)-')\n",
    "accre_df['day_used'] = accre_df['USEDTIME'].str.extract('(.*?)-')\n",
    "\n",
    "## Adds zeros to the day column where null\n",
    "accre_df['day_req'] = accre_df['day_req'].fillna(0)\n",
    "accre_df['day_used'] = accre_df['day_used'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting days to integers to use in converting to seconds\n",
    "accre_df['day_req'] = accre_df['day_req'].astype(int)\n",
    "accre_df['day_used'] = accre_df['day_used'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to timedelta to then use dt.total_seconds()\n",
    "accre_df['hours_min_sec_req'] =  pd.to_timedelta(accre_df['hours_min_sec_req'], unit='s')\n",
    "accre_df['hours_min_sec_used'] =  pd.to_timedelta(accre_df['hours_min_sec_used'], unit='s')\n",
    "\n",
    "accre_df['hours_min_sec_req'] = accre_df['hours_min_sec_req'].dt.total_seconds()\n",
    "accre_df['hours_min_sec_used'] = accre_df['hours_min_sec_used'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes total seconds columns \n",
    "accre_df['total_sec_req'] = (accre_df['day_req'] * 86400) + accre_df['hours_min_sec_req']\n",
    "accre_df['total_sec_used'] = (accre_df['day_used'] * 86400) + accre_df['hours_min_sec_used']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df['ACCOUNT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df['STATE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df['PARTITION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do any of the production partition nodes show an unusual number of failed jobs relative to the others? (Ignore Debug Partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see failure by nodes in the production partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df_failures = accre_df[\n",
    "    (accre_df['STATE'] == 'FAILED') &\n",
    "    (accre_df['PARTITION'] == 'production')\n",
    "]\n",
    "\n",
    "accre_df_failures = accre_df_failures.reset_index()\n",
    "\n",
    "accre_df_failures.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df_failures.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with 3,816,290 in our dataset and are now down to 395 failures after whittling it down to failures in the production partition. We're looking at a failure rate of .01%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df_failures['NODELIST'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DF from value_counts by renaming the axis and reseting the index\n",
    "failures_by_nodelist = accre_df_failures['NODELIST'].value_counts().rename_axis('NODELIST').reset_index(name='COUNTS')\n",
    "failures_by_nodelist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_by_nodelist['COUNTS'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of failures by node in this list 1.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_by_nodelist.plot(kind = 'hist', title = 'Failure Histogram', figsize = (10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the histogram, we have outliers off to the right with some others that are failing more regularly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_by_nodelist.plot(kind='box');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes that fail more than 3 times are considered outliers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_by_nodelist[failures_by_nodelist['COUNTS'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_by_nodelist.head(16).plot(\n",
    "    kind = 'bar', \n",
    "    x = 'NODELIST',\n",
    "    y = 'COUNTS',\n",
    "    title = 'Top 16 Failures by Node (Outliers)',\n",
    "    color = 'green', \n",
    "    figsize = (15,5),\n",
    "    rot = 25, \n",
    "    fontsize = 12.5\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at cn1273 specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cn1273_df = accre_df_failures[accre_df_failures['NODELIST'] == 'cn1273']\n",
    "cn1273_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Exit Codes, all of the jobs failured due to user error for cn1273! Perhaps we should only look into failures that occured due to the job or node (ex: Exit Code 0:1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df_failures[accre_df_failures['EXITCODE'].str.startswith('0:')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like every failure in the Production partition is due to user error. Let's see what accounts need the most help to avoid future failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df_failures['ACCOUNT'].value_counts().plot(kind ='bar', figsize=(10,5), rot=75);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accre_df_failures_by_account = accre_df_failures['ACCOUNT'].value_counts()\n",
    "accre_df_failures_by_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_square = dict(markerfacecolor='r', marker='s')\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.title('Outliers from Failures By Account', fontsize=16)\n",
    "plt.xlabel('Failures')\n",
    "plt.annotate(s = 'cep', xy = (128, 1.05), fontsize = 12,\n",
    "             xytext = (127, 1.25), arrowprops=dict(facecolor='black', shrink=0.1, width=1))\n",
    "plt.annotate(s = 'plantain', xy = (88, .95), fontsize = 12,\n",
    "             xytext = (81, .75), arrowprops=dict(facecolor='black', shrink=0.1, width = 1))\n",
    "plt.annotate(s = 'tips', xy = (65, 1.05), fontsize = 12,\n",
    "             xytext = (65, 1.25), arrowprops=dict(facecolor='black', shrink=0.1, width = 1))\n",
    "plt.boxplot(accre_df_failures_by_account,  \n",
    "            vert = False, \n",
    "            flierprops=red_square);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
