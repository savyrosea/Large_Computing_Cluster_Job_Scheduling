{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: CMS Account - Savannah Sew-Hee\n",
    "The CMS collaboration has an automated job submission system that runs jobs as \"cmslocal\" and \"cmspilot\".\n",
    "\n",
    "For these two users, jobs have internal system tests that will terminate their jobs early after approximately 30 minutes.\n",
    "\n",
    "Do any of their jobs that ended in under an hour also cluster on specific compute nodes, \n",
    "suggesting possbily unreliable systems? \n",
    "\n",
    "Check both “production” and “nogpfs” partitions. \n",
    "\n",
    "Look for commonly failing nodes and compare with other failed jobs.\n",
    "_____________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "from io import StringIO\n",
    "from datetime import time\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the CSV to use | instead of , to separate rows, then import [a selection] of the data as a dataframe\n",
    "for_pd = StringIO()\n",
    "with open('../data/accre-jobs-2020.csv') as accre:\n",
    "    for line in accre:\n",
    "        new_line = re.sub(r',', '|', line.rstrip(), count=12)\n",
    "        print (new_line, file=for_pd)\n",
    "\n",
    "for_pd.seek(0)\n",
    "\n",
    "accre_df = pd.read_csv(for_pd, sep='|')#[1000000:1005000] # add this to subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning accre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting time to seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making column for hours:min:sec\n",
    "accre_df['hours_min_sec_req'] = accre_df['REQTIME'].str[-8:]\n",
    "accre_df['hours_min_sec_used'] = accre_df['USEDTIME'].str[-8:]\n",
    "\n",
    "#making column for days\n",
    "accre_df['day_req'] = accre_df['REQTIME'].str.extract('(.*?)-')\n",
    "accre_df['day_used'] = accre_df['USEDTIME'].str.extract('(.*?)-')\n",
    "\n",
    "#filling null rows with zeros\n",
    "accre_df['day_req'] = accre_df['day_req'].fillna(0)\n",
    "accre_df['day_used'] = accre_df['day_used'].fillna(0)\n",
    "\n",
    "# converting to the correct type\n",
    "accre_df['day_req'] = accre_df['day_req'].astype(int)\n",
    "accre_df['day_used'] = accre_df['day_used'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to timedelta to then use total_seconds\n",
    "accre_df['hours_min_sec_req'] =  pd.to_timedelta(accre_df['hours_min_sec_req'], unit='s')\n",
    "accre_df['hours_min_sec_used'] =  pd.to_timedelta(accre_df['hours_min_sec_used'], unit='s')\n",
    "accre_df['hours_min_sec_req'] = accre_df['hours_min_sec_req'].dt.total_seconds()\n",
    "accre_df['hours_min_sec_used'] = accre_df['hours_min_sec_used'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making total seconds columns \n",
    "accre_df['total_sec_req'] = (accre_df['day_req'] * 86400) + accre_df['hours_min_sec_req']\n",
    "accre_df['total_sec_used'] = (accre_df['day_used'] * 86400) + accre_df['hours_min_sec_used']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning CMS Account Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting data for cms account\n",
    "cms_df = accre_df[accre_df['ACCOUNT']=='cms']\n",
    "\n",
    "#subsetting data to get rid of debug partition\n",
    "cms_df = cms_df[cms_df['PARTITION']!='debug']\n",
    "\n",
    "#subsetting data for only 'cmspilot' and 'cmslocal' users\n",
    "cms_df = cms_df[(cms_df['USER']=='cmspilot')|(cms_df['USER']=='cmslocal')]\n",
    "\n",
    "#printing how many CMS jobs including over an hour\n",
    "print(cms_df.shape)\n",
    "\n",
    "#subsetting for time under an hour\n",
    "cms_df = cms_df[cms_df['total_sec_used'] <= 3600]\n",
    "\n",
    "#getting only failed jobs\n",
    "#using state != to complete instead of exit code beacuse its built in their code to crash and error might not be reflected in exit code\n",
    "cms_failed = cms_df[cms_df['STATE'] != 'COMPLETED']\n",
    "cms_completed = cms_df[cms_df['STATE'] == 'COMPLETED']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examining the difference between a 'COMPLETED' job and exitcode '0:0'\n",
    "pd.crosstab(cms_df['EXITCODE'],cms_df['STATE']).apply(lambda x: (x/x.sum()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often are jobs canceling around 30 minutes for account CMS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at distribution of seconds to find spike\n",
    "#where jobs are canceling sround 30 min\n",
    "cms_df.hist(column = 'total_sec_used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many jobs ended between 500 and 2000 seconds\n",
    "#or 1000 and 1500 use this one second spike\n",
    "cms_jobs_ended_around_30_min = cms_df[(cms_df['total_sec_used'] < 1500) & (cms_df['total_sec_used'] > 1000)]\n",
    "\n",
    "print(\"Number of CMS Jobs Total:\")\n",
    "print(\"(699831, 19)\")\n",
    "print(\"Number of CMS Jobs Under Hour:\")\n",
    "print(cms_df.shape)\n",
    "print(\"Number of CMS Jobs Ended Around 30 Minutes:\")\n",
    "print(cms_jobs_ended_around_30_min.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what percent of jobs is this?\n",
    "print(str(round((263645/699831)*100,2)) + \"% are ending around 30 minutes\\nout of total CMS jobs (cmspilot/cmslocal users)\")\n",
    "print(\"\\n\")\n",
    "print(str(round((263645/447255)*100,2)) + \"% are ending around 30 minutes\\nout of jobs ending in less than an hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Failed Nodes for CMS Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_failed_nodes = cms_df['NODELIST'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = most_failed_nodes.plot(kind = 'bar', figsize = (8,6))\n",
    "ax.set_title('CMS Account: Nodes that Failed the Most',weight='bold', size='large')\n",
    "ax.set_xlabel('Node')\n",
    "ax.set_ylabel('Number of Time Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_failed_nodes.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of Times that Nodes Failed for CMS Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of failed nodes for new df for percents\n",
    "cms_failed['NODELIST'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of successful nodes for new df for percents\n",
    "cms_completed['NODELIST'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating df with top nodes to examine by percent of times failed\n",
    "CMS_nodes = {'NODE':['ng518','cn1314','cn394','ng734','cn475','cn1094','ng1112','cn449','cn1121','cn304','cn1394','cn408','cn1387','cn399','cn363','cn429','cn1398','cn312'],\n",
    "            'TIMES_FAILED':[16,12,11,10,9,9,9,9,9,9,8,8,8,8,8,8,8,8],\n",
    "            'TOTAL_TIMES_USED':[19352,12,347,4138,364,397,6171,400,465,298,408,446,249,415,339,306,550,407]}\n",
    "CMS_nodes_df = pd.DataFrame(CMS_nodes, columns = ['NODE','TIMES_FAILED','TOTAL_TIMES_USED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMS_nodes_df['PERCENT_FAILED'] = (CMS_nodes_df['TIMES_FAILED']/CMS_nodes_df['TOTAL_TIMES_USED'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotted with one outlier, maybe remove it to make it easier to see\n",
    "ax = CMS_nodes_df.sort_values('PERCENT_FAILED').plot.bar(x = 'NODE', y = 'PERCENT_FAILED', figsize = (8,6))\n",
    "ax.set_title('Percent Node Failed for CMS Account',weight='bold', size='large')\n",
    "ax.set_xlabel('Node')\n",
    "ax.set_ylabel('Percent of Times Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed cn 1314 to make it to make it easier to see,  label this graph\n",
    "CMS_nodes_without_cn1314 = CMS_nodes_df[CMS_nodes_df['NODE'] != 'cn1314']\n",
    "ax = CMS_nodes_without_cn1314.sort_values('PERCENT_FAILED').plot.bar(x = 'NODE', y = 'PERCENT_FAILED',figsize = (8,6))\n",
    "ax.set_title('Percent Node Failed for CMS Account (without Outlier CN1314)',weight='bold', size='large')\n",
    "ax.set_xlabel('Node')\n",
    "ax.set_ylabel('Percent of Times Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMS_nodes_df.sort_values('PERCENT_FAILED', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneeded columns\n",
    "accre = accre_df.drop([\"JOBID\",\"USER\", \"NODELIST\"], axis =1) # axis = 1 so that it works across our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new column is for requested memory per node\n",
    "accre['RMPN'] = accre['REQMEM'].str.extract('(.*)Mn$')\n",
    "\n",
    "#new column is for requested memory per core\n",
    "accre['RMPC'] = accre['REQMEM'].str.extract('(.*)Mc$')\n",
    "\n",
    "#new column is for requested memory per core\n",
    "accre['UM'] = accre['USEDMEM'].str.extract('(.*)M$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change RMPC,RMPN,UM colum to fill with na with 0\n",
    "accre['RMPC'] = accre['RMPC'].fillna('0')\n",
    "accre['RMPN'] = accre['RMPN'].fillna('0')\n",
    "accre['UM'] = accre['UM'].fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing types\n",
    "accre['RMPC']= accre['RMPC'].astype(str).astype(float)\n",
    "accre['RMPN']= accre['RMPN'].astype(str).astype(float)\n",
    "accre['UM']= accre['UM'].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is per core??? assume you multiply cpus by node this column will be RMPN times CPUS \n",
    "#3.5 is the average node to core ratio\n",
    "accre['RMPN'] = accre['RMPN'] /(accre['CPUS']/ accre['NODES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is per core??? update RMPC to add the RMPNEW column\n",
    "accre['RMPC'] = accre['RMPC'] + accre['RMPN']\n",
    "\n",
    "# remove unneeded columns\n",
    "accre = accre.drop([\"RMPN\"], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert used memory to cores \n",
    "accre['UM'] = (accre['UM'] /accre['CPUS'])/ accre['NODES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERCENT of request to actual used\n",
    "accre['PRU'] = (accre['UM']/accre['RMPC']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a weighted average function\n",
    "def wavg(group, avg_name, weight_name):\n",
    "    \"\"\" http://stackoverflow.com/questions/10951341/pandas-dataframe-aggregate-function-using-multiple-columns\n",
    "    In rare instance, we may not have weights, so just return the mean. Customize this if your business case\n",
    "    should return otherwise.\n",
    "    \"\"\"\n",
    "    d = group[avg_name]\n",
    "    w = group[weight_name]\n",
    "    try:\n",
    "        return (d * w).sum() / w.sum()\n",
    "    except ZeroDivisionError:\n",
    "        return d.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted average for all acounts\n",
    "wavg(accre, \"PRU\", \"total_sec_used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted average by account (best Optimizing to least)\n",
    "weighted_mem_accre_accounts = accre.groupby(\"ACCOUNT\").apply(wavg, \"PRU\", \"total_sec_used\").sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 at optimizing memory\n",
    "weighted_mem_accre_accounts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom 10 at optimizing memory\n",
    "weighted_mem_accre_accounts.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
